print("********************************************************************************************************************")
print("Program starts here")
print("********************************************************************************************************************")


print("********************************************************************************************************************")
print("Import libraries")
print("********************************************************************************************************************")
import warnings
warnings.filterwarnings("ignore")
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.naive_bayes import MultinomialNB, GaussianNB

from sklearn.feature_extraction.text import CountVectorizer
from nltk.tokenize import RegexpTokenizer


print("********************************************************************************************************************")
print("Load dataset")
print("********************************************************************************************************************")
data = pd.read_csv('IMDB_data.csv')


print("********************************************************************************************************************")
print("Data Analysis")
print("********************************************************************************************************************")
print("Data Head  is : \n",data.head(3))
print("------------------------------------------------------------------------------------")
print("Data Shape is : \n",data.shape)
print("------------------------------------------------------------------------------------")
print("Data Desc  is : \n",data.describe())
print("------------------------------------------------------------------------------------")
print("Classes info  :", data.groupby("sentiment").size())

print("********************************************************************************************************************")
print("Pre-Prcoess Data : Bag of Word Vectorization using Count Vectorizer")
print("********************************************************************************************************************")
token = RegexpTokenizer(r'[a-zA-Z0-9]+')
cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)
text_counts = cv.fit_transform(data['Sentence'])
print("------------------------------------------------------------------------------------")
i=0
print("First 10 vocabulary_ words : ")
for vword in cv.vocabulary_.keys():
    print("Vocabulary id of ",vword, " is \t\t",cv.vocabulary_[vword])
    i+=1
    if i>10:
        break
print("------------------------------------------------------------------------------------")
i=0
print("First 10 stop words : ")
for sword in cv.get_stop_words():
    i+=1
    print(sword)
    if i>10:
        break
print("------------------------------------------------------------------------------------")
print("Out feature names are : ",cv.get_feature_names_out()[0:10])


print("********************************************************************************************************************")
print("Prepare datasets for both trainig and testing")
print("********************************************************************************************************************")
X_train, X_test, Y_train, Y_test = train_test_split(text_counts, data['Sentiment'], test_size=0.25, random_state=5)


print("********************************************************************************************************************")
print("Init model")
print("********************************************************************************************************************")
model = MultinomialNB()


print("********************************************************************************************************************")
print("Train model")
print("********************************************************************************************************************")
model.fit(X_train, Y_train)


print("********************************************************************************************************************")
print("Model validation")
print("********************************************************************************************************************")
predicted = model.predict(X_test)


print("********************************************************************************************************************")
print("Validate using metrics")
print("********************************************************************************************************************")
accuracyScore = round(accuracy_score(predicted, Y_test) * 100,2)
print("Accuracuy Score: \n",accuracyScore )
print("------------------------------------------------------------------------------------")
confusionMatrix = confusion_matrix(predicted, Y_test)
print("Confusion matrix: \n",confusionMatrix )

print("********************************************************************************************************************")
print("Program ends here")
print("********************************************************************************************************************")
